{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Write a function compute_GridSearchCV which accepts the Kernel and\n",
    "regularization parameters as inputs and returns the Mean cross-validated score \n",
    "of the best_estimator, denoted with best_score_ of the models with the below-mentioned hyperparameters:\n",
    "Split the Iris dataset into train and test sets with 70:30 ratio\n",
    "Import svm.SVC as 'model'\n",
    "kernels = ['linear' , 'rbf']\n",
    "Regularization = [1,15,25]\n",
    "gamma = 'auto'\n",
    "Cross Validation = 4\n",
    "random_state=0\n",
    "\"\"\"\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('Social_Network_Ads.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  2]\n",
      " [ 8 24]]\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Purchased'])\n",
    "y = df['Purchased']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "model = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[469   0   1   0   0   5   1   1   1   0]\n",
      " [  1 555   2   4   0   1   1   1   3   0]\n",
      " [  5   4 479   6   9   1   3   6   7   1]\n",
      " [  3   3  13 462   0  19   0   3   9   4]\n",
      " [  2   0   6   0 468   1   2   4   1  16]\n",
      " [ 14   0   0  18   2 405   3   2   7   9]\n",
      " [  1   2   2   0   6   9 471   0   0   0]\n",
      " [  0   2   4   1   7   1   0 483   0   6]\n",
      " [  3  10  11  15   0  19   6   3 396   3]\n",
      " [  3   6   1   2  21   0   0  26   2 435]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "From the MNIST dataset, consider the first 20,000 data samples as training data \n",
    "and the next 5,000 data samples as test data. Fit a pipeline with MinMaxScaler and\n",
    "a classifier with SVC, linear kernel, one vs rest decision_function_shape and\n",
    "class_weight=None to this dataset.\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "X_train = X[:20000]\n",
    "y_train = y[:20000]\n",
    "X_test = X[20000:25000]\n",
    "y_test = y[20000:25000]\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "pipe_1 = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"classifier\",SVC(kernel=\"linear\", decision_function_shape=\"ovr\", class_weight=None)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_1.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_1.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4623"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum=0\n",
    "for i in range(len(cm)):\n",
    "    sum+= cm[i][i]\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9240407420002983\n",
      "0.9233855313071502\n",
      "0.9233432645058162\n"
     ]
    }
   ],
   "source": [
    "# Find precision, recall and f1_Score?\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "\n",
    "print(precision_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(recall_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "print(f1_score(y_test, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9723258740744227"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Consider the MNIST dataset, split it into training and test set in 50:50 ratio\n",
    "with random_state = 42. Fit a SVM model using pipeline with StandardScalar, SVM\n",
    "classifier kernel='poly' and degree = 3, decision_function_shape='ovr'and\n",
    "class_weight='balanced', C=10. Train the model on training data, and make\n",
    "predictions for test data. Generate the Classification report and choose the\n",
    "correct value for weighted avg of f1_score\n",
    "\"\"\"\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "X, y = fetch_openml(\"mnist_784\", version=1, return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaling', StandardScaler()),\n",
    "    ('svm', SVC(kernel='poly', degree=3,decision_function_shape='ovr',class_weight='balanced',C=10))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "f1_score(y_test,y_pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the Iris dataset into train and test set with 70:30 ratio (Take random state value as 42)\n",
    "Import svm.SVC as 'model'\n",
    "kernel as 'poly', regularization parameter as 10 and gamma as 'auto'\n",
    "Train the model and mark the computed accuracy score for test data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkout the Assignments netlify website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
